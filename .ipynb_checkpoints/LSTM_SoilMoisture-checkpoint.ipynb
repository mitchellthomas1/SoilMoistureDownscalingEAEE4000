{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d4b78d3-31de-4fa7-923a-7e2e1fc46697",
   "metadata": {},
   "source": [
    "This notebook shows the application of an LSTM to downscaling soil moisture\n",
    "\n",
    "By Mitchell Thomas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83ff91fe-7661-4ef3-bbac-513674a4b01c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/fx/kh_2yrm96pbg2rdsgbbj16mr0000gn/T/ipykernel_56954/342024814.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mimportdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mreturn_all_regions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "from glob import glob\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import Sequential\n",
    "from utils import *\n",
    "\n",
    "from importdata import return_all_regions\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "plt.rcParams['savefig.dpi'] = 400\n",
    "plt.rcParams['font.size'] = 13\n",
    "plt.rcParams[\"legend.frameon\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2102af83-e95b-4cfe-9d54-691a36de1d22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29a2944f",
   "metadata": {},
   "source": [
    "## Section 1. Pre-training LSTM on S1, S2, Landcover, Field Capacity, and TPI at 9 km"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973ad626-6592-4328-990e-c24be36dd045",
   "metadata": {},
   "source": [
    "### 1. data preprocssing: prepare data for training & test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50356eca-fd74-47c6-b2af-3928112538fc",
   "metadata": {},
   "source": [
    "#### import data as training & test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efb9458-c647-4751-b45e-3cadce83690d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_9km_data = return_all_regions()\n",
    "\n",
    "\n",
    "# # Training set\n",
    "# train_files = [\"historical\", \"ssp585\", \"ssp126\", \"ssp370\",\"hist-aer\",\"hist-GHG\"]\n",
    "# X_train_xr, X_length  = prepare_predictor(train_files,train_path)\n",
    "# y_train_xr, y_length  = prepare_predictand(train_files,train_path)\n",
    "\n",
    "# # Test set\n",
    "# X_test_xr, _ = prepare_predictor('ssp245', data_path=test_path,time_reindex=False)\n",
    "# y_test_xr, _ = prepare_predictand('ssp245',data_path=test_path,time_reindex=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3978009c-b831-4b1a-a6ac-b0bc6b81884a",
   "metadata": {},
   "source": [
    "#### select relevant variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd1809e-0068-427f-bfde-cb246804e9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df = pd.DataFrame({\"CO2\": X_train_xr[\"CO2\"].data,\n",
    "                           \"CH4\": X_train_xr[\"CH4\"].data\n",
    "                          }, index=X_train_xr[\"CO2\"].coords['time'].data)\n",
    "\n",
    "X_test_df  = pd.DataFrame({\"CO2\": X_test_xr[\"CO2\"].data,\n",
    "                           \"CH4\": X_test_xr[\"CH4\"].data\n",
    "                          }, index=X_test_xr[\"CO2\"].coords['time'].data)\n",
    "\n",
    "\n",
    "y_train_df = y_train_xr[\"tas\"].stack(dim=[\"latitude\", \"longitude\"])\n",
    "y_train_df = pd.DataFrame(y_train_df.to_pandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465f3374-067e-47d3-a7ae-b4826509eab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c650fb-6e8a-468c-bd66-155affbabab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5210ee-295a-41b8-8af6-3a21075155a6",
   "metadata": {},
   "source": [
    "#### Data normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a914fc9-a6ef-45b5-ba2b-34c06f2d2ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardization\n",
    "mean, std = X_train_df.mean(), X_train_df.std()\n",
    "\n",
    "X_train_df   = (X_train_df - mean)/std\n",
    "X_test_df    = (X_test_df - mean)/std\n",
    "\n",
    "X_train = X_train_df.to_numpy()\n",
    "y_train = y_train_df.to_numpy()\n",
    "X_test = X_test_df.to_numpy()\n",
    "\n",
    "print(X_train.shape,y_train.shape,X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b9765e-91ea-4f88-b609-618b595f0081",
   "metadata": {},
   "source": [
    "#### Reshape data to feed into the LSTM model\n",
    "\n",
    "The LSTM needs data with the format of **[samples, time steps, features]**\n",
    "\n",
    "Here the lag time step is set to **5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052e6d4b-aff4-409d-a42f-bf0bdb7023e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = np.cumsum(X_length) - X_length\n",
    "end   = np.cumsum(X_length)\n",
    "\n",
    "slider = 5\n",
    "X_train_all = []\n",
    "y_train_all = []\n",
    "\n",
    "for i in range(len(X_length)):\n",
    "    \n",
    "    X_subset = X_train[start[i]:end[i],:]\n",
    "    y_subset = y_train[start[i]:end[i],:]\n",
    "    \n",
    "    X_subset = np.array([X_subset[i:i+slider] for i in range(0, X_length[i]-slider+1)])\n",
    "    y_subset = np.array([[y_subset[i+slider-1]] for i in range(0, X_length[i]-slider+1)])\n",
    "    \n",
    "    X_train_all.append(X_subset)\n",
    "    y_train_all.append(y_subset)\n",
    "    \n",
    "X_train = np.concatenate(X_train_all,axis=0)\n",
    "y_train = np.concatenate(y_train_all,axis=0)\n",
    "X_test  = np.array([X_test[i:i+slider] for i in range(0, X_test.shape[0]-slider+1)])\n",
    "print(X_train.shape,y_train.shape,X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44dbaa7-a17e-49be-99af-3b48c6d49228",
   "metadata": {},
   "source": [
    "### 2. Define the LSTM structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66690c2-3d72-446b-b67e-6408bbfb461d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set hyperparameters\n",
    "n_neuron       = 64\n",
    "activation     = 'relu'\n",
    "num_epochs     = 50\n",
    "learning_rate  = 0.001\n",
    "minibatch_size = 64\n",
    "model_num      = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cc2495-cf2d-477c-a9a3-e818fda1a4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = Sequential()\n",
    "lstm_model.add(LSTM(n_neuron,input_shape=(X_train.shape[1],X_train.shape[2]),\n",
    "               return_sequences=True,activation=activation))\n",
    "lstm_model.add(LSTM(n_neuron,return_sequences=False,\n",
    "               activation=activation))\n",
    "lstm_model.add(Dense(n_neuron,activation=activation))\n",
    "lstm_model.add(Dense(y_train.shape[-1],activation='linear')) \n",
    "\n",
    "lstm_model.compile(loss='mse',optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate))\n",
    "\n",
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb46739b-6c29-4fa5-bc05-af04d08f300d",
   "metadata": {},
   "source": [
    "### 3. Train & save the NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebda28cd-8aa3-4413-8669-1eb181596246",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "history = lstm_model.fit(X_train, y_train, \n",
    "                        batch_size = minibatch_size,\n",
    "                        epochs = num_epochs,\n",
    "                        validation_split=0.2, verbose=1,\n",
    "                        callbacks=[early_stop],\n",
    "                        shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475b2f5c-3308-4be2-8f4e-9c131c3e3b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(cwd,'saved_model')\n",
    "make_dir(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fe69ec-ee46-4e89-af42-5cccf0dbb44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the entire model to a HDF5 file.\n",
    "# The '.h5' extension indicates that the model should be saved to HDF5.\n",
    "lstm_model.save(os.path.join(model_path,'LSTM_model.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bc67b5-a593-4235-921e-68dde3afaa58",
   "metadata": {},
   "source": [
    "### 4. Evaluate the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f641ec4d-6ec4-49b6-a892-6c9c58fc307b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload the saved model\n",
    "lstm_model = load_model(os.path.join(model_path,'LSTM_model.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08819cb-1598-43a2-ae99-6eccc8ea82f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pre = lstm_model.predict(X_test)\n",
    "y_test_pre = y_test_pre.reshape(y_test_pre.shape[0], 96, 144)\n",
    "\n",
    "y_test_pre = xr.Dataset(coords={'time': X_test_xr.time.values[slider-1:], \n",
    "                               'latitude': X_test_xr.latitude.values, \n",
    "                               'longitude': X_test_xr.longitude.values},\n",
    "                       data_vars=dict(tas=(['time', 'latitude', 'longitude'], y_test_pre)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d00dbcd-f789-43c4-ad92-844d1c59773b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(15,12),ncols=2,nrows=3)\n",
    "\n",
    "yrs = [2030, 2050, 2100]\n",
    "vmin, vmax    = -6, 6\n",
    "cmap = 'RdBu_r'\n",
    "y_test_pre.tas.sel(time=yrs[0]).plot(ax=axes[0,0], vmin=vmin, vmax=vmax,cmap=cmap)\n",
    "y_test_xr.tas.sel(time=yrs[0]).plot(ax=axes[0,1], vmin=vmin, vmax=vmax,cmap=cmap)\n",
    "\n",
    "y_test_pre.tas.sel(time=yrs[1]).plot(ax=axes[1,0], vmin=vmin, vmax=vmax,cmap=cmap)\n",
    "y_test_xr.tas.sel(time=yrs[1]).plot(ax=axes[1,1], vmin=vmin, vmax=vmax,cmap=cmap)\n",
    "\n",
    "y_test_pre.tas.sel(time=yrs[2]).plot(ax=axes[2,0], vmin=vmin, vmax=vmax,cmap=cmap)\n",
    "y_test_xr.tas.sel(time=yrs[2]).plot(ax=axes[2,1], vmin=vmin, vmax=vmax,cmap=cmap)\n",
    "\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    # left column: model prediction\n",
    "    if i % 2 == 0:\n",
    "        ax.set_title(f'tas model prediction (year = {yrs[i//2]})',fontweight='bold')\n",
    "    # right column: truth tas from ssp245 simulations\n",
    "    else:\n",
    "        ax.set_title(f'tas truth (year = {yrs[i//2]})',fontweight='bold')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a505c85-dbe6-4167-a376-7b3abf694a9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a55a262",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a88118",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
